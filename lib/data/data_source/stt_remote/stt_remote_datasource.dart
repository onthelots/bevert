import 'dart:typed_data';
import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:http_parser/http_parser.dart';

abstract class WhisperDataSource {
  Future<String> transcribeAudio(Uint8List audioData);
}

class WhisperDataSourceImpl implements WhisperDataSource {
  final Dio dio;

  WhisperDataSourceImpl(this.dio);

  @override
  Future<String> transcribeAudio(Uint8List audioData) async {
    final apiKey = dotenv.env['OPENAI_API_KEY']!;
    final filename = 'audio_${DateTime.now().millisecondsSinceEpoch}.wav';

    print("ğŸ”¹ Whisper í˜¸ì¶œ ì¤€ë¹„");
    print("ğŸ”¹ íŒŒì¼ í¬ê¸°: ${audioData.length} bytes");
    print("ğŸ”¹ íŒŒì¼ ì´ë¦„: $filename");
    print("ğŸ”¹ API Key ì¡´ì¬ ì—¬ë¶€: ${apiKey.isNotEmpty}");

    final formData = FormData.fromMap({
      'file': MultipartFile.fromBytes(audioData, filename: filename),
      'model': 'whisper-1',
    });

    try {
      final response = await dio.post(
        'https://api.openai.com/v1/audio/transcriptions',
        data: formData,
        options: Options(
          headers: {
            'Authorization': 'Bearer $apiKey',
            // multipart/form-dataëŠ” FormData ì‚¬ìš© ì‹œ ìë™ ì§€ì •ë¨
            //'Content-Type': 'multipart/form-data',
          },
          validateStatus: (status) {
            // 200ë²ˆëŒ€ë¿ë§Œ ì•„ë‹ˆë¼ ëª¨ë“  ìƒíƒœì½”ë“œ í™•ì¸
            return true;
          },
        ),
      );

      print("ğŸ”¹ HTTP ìƒíƒœ ì½”ë“œ: ${response.statusCode}");
      print("ğŸ”¹ Response data: ${response.data}");

      if (response.statusCode == 200) {
        return response.data['text'] ?? '';
      } else {
        throw Exception('Whisper API error: ${response.statusCode} - ${response.data}');
      }
    } catch (e, st) {
      print("âŒ Whisper í˜¸ì¶œ ì˜ˆì™¸ ë°œìƒ: $e");
      print(st);
      rethrow;
    }
  }
}
